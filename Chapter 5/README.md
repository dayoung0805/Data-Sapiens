# 데이터베이스는 분석을 위해 최적화 되어야   
데이터의 용량과 처리 속도는 지난 수십 년간 계속 커지며 빨라져 왔고, 그 자체는 이미 뉴스 거리도 안 된다.    

빅데이터라는 말 자체가 '크기'를 표현하고 있지만, 크기와 속도만 자랑하는 것은 본질을 놓치는 첩경이며 많은 실망을 가져오게 되어있다.    

그것이 내년이건 내후년이건, 운이 좋아서 앞으로 몇 년을 두고 그 말을 우려먹을 수 있건 간에, 데이터로 수익을 올리거나 지출을 가시적으로 줄이지 못하면 심판의 날은 반드시 오기 마련이다.   


빅데이터는 '사람들의 질문에 대한 대답'의 형태로 이루어져야만 사업이나 의사결정에 도움이 된다.   

역설적으로 표현하자면, 빅데이터는 "반드시 작아져야만 하는 것"이라고 말할 수 있다.   

### 데이터가 작아지려면,  
### 1) Cut down the noise, 즉 데이터에서 잡음을 줄이고

### 2) Provide insight, not data, 즉 데이터가 아닌 '통찰력이 담긴 내용'을 주어야 한다.   

그것은 마치 금 한 덩어리를 얻기 위해 많은 잡석을 버리는 것과 비슷한 이치이며, 그것이 큰 덩어리의 데이터에서 알맹이로 줄여 나가는 과정.

### 데이터를 잘 정리를 못하면 고치느라 시간낭비    
### 일이 잘못되는 경우 많은 부분은 그 통계를 다루는 자체의 문제가 아니라 데이터나 그 주변 환경이 잘못되어 있기 때문이다.   
즉 통계를 사용하기 이전에 데이터베이스 구조 자체에 문제가 있거나 많은 변수들이 제대로 정리가 되어 있지 않은 것이며, 혹은 모델을 짠 이후 그것을 적용할 때 뭔가가 잘못된 것이다.   

그 모델링의 "Before" 단계에는 data hygiene, conversion, categorization, summarization 등이 정확하고 일관되게 이루어져야 하며, "After" 단계에는 score application, validation, selection 등이 빠르고 정확하게 돌아가야 한다.   

그런 것이 제대로 안되면 미국에서 흔히 쓰는 Garbarge-in-garbage-out이란 표현이 딱 어울리게 된다.   

쓰레기가 들어가면 쓰레기가 나온다는 말인데, 쓰레기 같이 지저분한 데이터도 공정을 제대로 거치면 재활용품처럼 재탄생 되는 법이다.  

데이터 비즈니스란 워난 마지막으로 데이터에 손을 댄 사람이 그 전에 데이터를 만진 사람들의 오류까지 다 책임지고 고쳐야 하는 것이 옳은 것이긴 하지만, 통계학 석사나 박사들인 온 종일 남의 실수만 고치려고 그 어려운 공부를 마친 게 아닌 것은 분명하다.   

게다가 통계 전문가들은 그런 데이터 일에 능숙하지도 않고 그 방면에 트레이닝을 받은 사람들도 아니다.    

상황이 이러니 미국에서도 데이터 사이언티스트나 애널리스트란 타이틀을 가지려면 데이터를 잘 고칠 줄도 알아야 한다는 말도 나온다. 

그건 마치 자동차 경주하는 사람이 자동차 수리 능격도 뛰어나야만 성공할 수 있다는 말과 비슷하다.     

애널리스트나 통계 전문가를 트레이닝할 때 모델링을 포함한 데이터 일은 "Making the best of what you've got", 즉 주어진 데이터를 가장 효율적으로 사용하도록 하는 것이란 말을 한다.   

왜냐하면 이 세상에는 완벽한 데이터란 없기 때문이다.    

### 데이터베이스를 이러한 애널리틱스(analytics), 특히 통계적 모델에 최적화가 되어 있어야 한다.
그런 환경이 제대로 이루어져 있으면 sampling과 scoring은 그야말로 일상적인 일이 될 것이다.    

통계 전문가들은 늘 데이터나 고치고 있는 대신에 타킷과 방법론에 대해 대부분의 시간을 보낼 수 있게 될 것이다.   

그리고 그런 환경이 이루어지면 더 기본적인 query난 reporting도 훨씬 수월하게 되는데 예외가 없다.  

리포트들도 더 일관된 정보를 더 효율적으로 포함하게 될 것이다.   

### 고등 분석에 최적화된 데이터베이스의 조건 
### 1) 모든 테이블들이 제대로 연결이 되어 있고 match key가 일관성이 있어야 한다.   
특히 개인이나 사업체 등을 표현하는 ID들이 제대로 관리되어야 그러한 대상을 타깃으로 삼을 수 있게 된다.    

### 2) 타깃 대상 혹은 사용 목적에 따라 데이터가 개인, 가구, 이메일, 사업체, 혹은 제품별로 요약되어 있어야 한다.   
매번 요약과 집적 과정을 반복해가면서 일을 진행하다 보면 시간도 낭비하게 되고 일관성도 눈에 보이게 떨어진다.  

### 3) 숫자로 표현된 데이터, 즉 가격, 지불액, 구매건수, 날짜, 구매 간 시간 간격 등이 표준화되고 결여된 데이터(missing data)가 제대로 처리되어 단순한 "0"과 구별되어 관리되어야 한다.    
알 수 없는 숫자는 0이 아니다.

### 4) 숫자가 아닌 범주적 데이터(categorical data), 혹은 문자적 데이터(character data)도 편집 수정되고 미리 정해진 카테고리별로 구분 관리되어야 한다.    

### 5) 결여된 데이터, 즉 Missing Data는 데이터베이스를 요약하다 보면 필연적으로 생기는 부산물인데, 그것도 정해진 룰에 따라 채워지던지 수학적으로 새로 impute, 즉 가치가 매겨져야 한다.   
많은 오류는 없는 데이터를 보완해 채워 넣는 과정에서 일어난다.  

### 6) 외부의 데이터도 제대로 맞추어져서 기존 기록들에 연결이 되어야 한다.   
소스가 다른 데이터를 함치는 과정에서도 많은 오류가 발생한다.   
아예 합쳐져 있지 않으면 통계적으로 사용하는 것이 불가능해지는데, 그런 데이터베이스도 허다하다.    




